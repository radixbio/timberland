job "${prefix}yugabyte-masters" {
  all_at_once = false

  constraint {
    attribute = "$${attr.kernel.name}"
    operator = "="
    value = "linux"
  }

  constraint {
    operator = "distinct_hosts"
    value = "true"
  }

  datacenters = ["dc1"]

%{ for i in range(dev ? 1 : quorum_size) ~}
  group "yb-masters-group-${i}" {

    count = 1

    volume "ybmaster_data" {
      type = "host"
      read_only = false
      source = "ybmaster_data"
    }

    task "yb-master-task" {

      volume_mount {
        volume = "ybmaster_data"
        destination = "/ybmaster_data"
        read_only = false
      }

      config {
        image = "yugabytedb/yugabyte:latest"
        command = "bash"
        // we hardcode 127.0.0.1:xxxx for the master addresses so that they're in the same order on every yugabyte node so they can agree on a leader
        // we need to increment the rpc bind port and advertised port because yugabyte gets sad if multiple nodes have the same advertised address
        args = ["-c", "/home/yugabyte/bin/yb-master --fs_data_dirs=/ybmaster_data --replication_factor=${ dev ? 1 : quorum_size} --rpc_bind_addresses=0.0.0.0:${7100 + i} --server_broadcast_addresses=127.0.0.1:${ 7100 + i} --use_private_ip=never --master_addresses=%{ for j in range(dev ? 1 : quorum_size) ~}127.0.0.1:${ 7100 + j },%{ endfor ~}"]
        auth_soft_fail = false
        privileged = false
        cap_add = []
      }

      driver = "docker"
      kill_timeout = "5s"
      kill_signal = "SIGINT"
      leader = false

      resources {
        cpu = 250
        memory = 1000
      }

      shutdown_delay = "0s"
    }

    network {
      mbits = 10
      mode = "bridge"
    }

    // don't need to increment the port for this because it doesn't need to talk to anything besides the ingress gateway - it's just a web UI
    service {
      name = "yb-master-${i}-head"
      port = 7000
      tags = ["${prefix}"]
      address_mode = "auto"

      connect {
        sidecar_service {

        }
      }

      check {
        type = "http"
        name = "yb-master-health-${i}"
        path = "/status"
        interval = "30s"
        timeout = "5s"
        expose = true
      }
    }

    // the service needs to be on the same port as the rpc bind port - ${ 9100 + i }
    service {
      name = "yb-masters-rpc-${i}"
      port = ${ 7100 + i }
      tags = ["${prefix}"]
      address_mode = "auto"

      connect {
        sidecar_service {
          proxy {


%{ for j in range(dev ? 1 : quorum_size) ~}
          // we list the master addresses as 127.0.0.1:${7100 + j } (7100 + j), so we need to make sure all the masters are accessible at
          // ports in the range [7100, 7100 + quorum_size]. this node is already bound to ${ 7100 + i} (7100 + j),
          // so bind the rest of the yugabyte nodes (via local_bind_port) to each port in the rest of the range
            upstreams {
              destination_name = "yb-tserver-connect-${j}"
              local_bind_port = ${ 9100 + j }
            }
${ i == j ? "" : <<-EOT
            upstreams {
              destination_name = "yb-masters-rpc-${j}"
              local_bind_port = ${ 7100 + j }
            }
            EOT
}
%{ endfor ~}
          }
        }
      }

      check {
        type = "script"
        name = "yb-master-${i}-health"
        task = "yb-master-task"
        command = "bash"
        // make sure that a master on this node's port exists in the list of all masters
        args = ["-c", "/home/yugabyte/bin/yb-admin -master_addresses %{ for j in range(dev ? 1 : quorum_size) }127.0.0.1:${ 7100 + j },%{ endfor } list_all_masters | tr ':' ' ' | awk '{print $3}' | grep -v RPC | grep ${ 7100 + i }"]
        interval = "30s"
        timeout = "5s"
      }
    }
  }
%{ endfor ~}

  namespace = "default"
  priority = 50
  region = "global"
  type = "service"

  update {
    max_parallel = 1
    health_check = "checks"
    min_healthy_time = "10s"
    healthy_deadline = "5m"
    progress_deadline = "10m"
    auto_revert = false
    canary = 0
    stagger = "10s"
  }

}